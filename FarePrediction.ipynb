{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from fancyimpute import KNN\n",
    "from ggplot import *\n",
    "import warnings\n",
    "import pickle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To remove warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir= input(\"Please Enter wrking Directory\")\n",
    "os.chdir (working_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read  csv data and save in a variable\n",
    "train_file =  input(\"Please enter train data file path: (CSV)\")\n",
    "test_file =  input(\"Please enter test data file path: (CSV)\")\n",
    "train = pd.read_csv(train_file)\n",
    "test = pd.read_csv(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleanup Process"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Convert datatypes for both train and test data\n",
    "----------------pickup_datetime --> year/month/date/weekday/hourn\n",
    "----------------pickup lat/long and dropoff lat/long -->distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"fare_amount\"] = pd.to_numeric(train[\"fare_amount\"], errors = \"coerce\")\n",
    "for i in [train,test]:\n",
    "    i[\"pickup_datetime\"] = pd.to_datetime(i[\"pickup_datetime\"], errors =\"coerce\")\n",
    "    \n",
    "    i[\"year\"] = i[\"pickup_datetime\"].dt.year\n",
    "    i[\"year\"] = (i[\"year\"]).astype(\"object\")\n",
    "    i[\"month\"] = i[\"pickup_datetime\"].dt.month\n",
    "    i[\"month\"] = (i[\"month\"]).astype(\"object\")\n",
    "    i[\"day\"] = i[\"pickup_datetime\"].dt.day\n",
    "    i[\"day\"] = (i[\"day\"]).astype(\"object\")\n",
    "    i[\"hour\"] = i[\"pickup_datetime\"].dt.hour\n",
    "    i[\"hour\"] = (i[\"hour\"]).astype(\"object\")\n",
    "    i[\"weekday\"] = i[\"pickup_datetime\"].dt.dayofweek\n",
    "    i[\"weekday\"] = (i[\"weekday\"]).astype(\"object\")\n",
    "    i[\"pickup_datetime\"] = i[\"pickup_datetime\"].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate distance between pickup and dropoff\n",
    "def havrsine_distance(lat1, long1, lat2, long2):\n",
    "    data = [train, test]\n",
    "    for i in data:\n",
    "        R = 6371  #radius of earth in kilometers\n",
    "        phi1 = np.radians(i[lat1])\n",
    "        phi2 = np.radians(i[lat2])\n",
    "    \n",
    "        delta_phi = np.radians(i[lat2]-i[lat1])\n",
    "        delta_lambda = np.radians(i[long2]-i[long1])\n",
    "    \n",
    "        a = np.sin(delta_phi / 2.0) ** 2 + np.cos(phi1) * np.cos(phi2) * np.sin(delta_lambda / 2.0) ** 2\n",
    "    \n",
    "        c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n",
    "    \n",
    "        d = (R * c) #in kilometers\n",
    "        i['distance'] = d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "havrsine_distance('pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re order columns, and put fare_amount in last column as this is the target variable \n",
    "train = train.reindex(list(train.columns[1:])+[\"fare_amount\"],axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "------------------------Check Anamolies and remove them-------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#There are some anamolies we need to remove\n",
    "#Longitude valid range  be +/-180 degree\n",
    "#Latitude range is  +/- 90, but in pickup latitude max is 401.08 which is invalid\n",
    "#Passenger count minimum is 0 which is not possible and maximum is 5345 which is also unreal\n",
    "#so lets assume maximum passenger count be 20 ( lets assume cab can be  is a mini bus too)\n",
    "#fare amount cannot be negative\n",
    "#So we need to remove these anomalies\n",
    "\n",
    "\n",
    "train =  train[((train['pickup_longitude'] > -180) & (train['pickup_longitude'] < 180)) & \n",
    "               ((train['dropoff_longitude'] > -180) & (train['dropoff_longitude'] < 180)) & \n",
    "               ((train['pickup_latitude'] > -90) & (train['pickup_latitude'] < 90)) & \n",
    "               ((train['dropoff_latitude'] > -90) & (train['dropoff_latitude'] < 90)) & \n",
    "               (train['passenger_count'] > 0) & (train['passenger_count'] <=20) & (train['fare_amount']>0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical = ['pickup_longitude', 'pickup_latitude',\n",
    "       'dropoff_longitude', 'dropoff_latitude', 'passenger_count', 'distance','fare_amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['pickup_datetime', 'year',\n",
    "       'month', 'day', 'hour', 'weekday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outliers in Numerical Variables\n",
    "#boxplot to visualise outlier\n",
    "%matplotlib inline\n",
    "plt.boxplot(train[\"distance\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can see there are some outliers in distance\n",
    "# lets count outliers if they are less then remove them\n",
    "train.loc[(train[\"distance\"]>200),\"distance\"].count()\n",
    "# the outliers are only 23 out of 15906 so we can remove it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove distance outliers\n",
    "train = train.drop(train.loc[(train[\"distance\"]>200),:].index, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(train[\"fare_amount\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can see there are some outliers in farre_amount\n",
    "# lets count outliers if they are less then remove them\n",
    "train.loc[(train[\"fare_amount\"]>200),\"fare_amount\"].count()\n",
    "# the outliers are only 4 out of 15883 so we can remove it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove outliers in fare_amount\n",
    "train = train.drop(train.loc[(train[\"fare_amount\"]>200),:].index, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scatter plot between distance and fare amount \n",
    "from ggplot import *\n",
    "\n",
    "ggplot( aes(x = 'distance', y = \"fare_amount\"),data = train) + geom_point()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In scatter plot we can see that at some points where distance is 0, fare is not 0 so we need  count these anamolies\n",
    "train.loc[(train[\"distance\"]==0)&train[\"fare_amount\"]>0,\"distance\"].count()\n",
    "#this is 454 and a 2% of total data so we can remove them as well\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(train.loc[((train[\"distance\"]==0)&train[\"fare_amount\"]>0),:].index, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarly if fare is 0 then distance cannot be >0\n",
    "train.loc[(train[\"fare_amount\"]==0)&train[\"distance\"]>0,\"fare_amount\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check observations when fare and distance both 0,\n",
    "train.loc[(train[\"fare_amount\"]==0)&(train[\"distance\"]==0),\"fare_amount\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove rows where passenger count is 0\n",
    "train = train.drop(train.loc[(train[\"passenger_count\"]==0),:].index, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "----------------------------------Missing data Analysis------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_val = pd.DataFrame(train.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there is only one row which has null value So we can remove it\n",
    "train  = train.drop(train.loc[(train[\"year\"].isnull()),:].index, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can remove pickup_datetime as it doesnt have much information in general\n",
    "train = train.drop(['pickup_datetime'], axis = 1)\n",
    "test = test.drop(['pickup_datetime'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work on given test data variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[:,\"passenger_count\"] = train.loc[:,\"passenger_count\"].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"processed_train_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualaization and  Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Correlation analysis As all data is Numerical\n",
    "#Assume that there should be no dependency between independent variables \n",
    "#Assume that there should be high dependency between independent variables and independent variable\n",
    "#Correlation plot\n",
    "train_corr = train.loc[:,numerical]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the width and hieght of the plot\n",
    "f, ax = plt.subplots(figsize=(7, 5))\n",
    "\n",
    "#Generate correlation matrix\n",
    "corr = train_corr.corr()\n",
    "\n",
    "#Plot using seaborn library\n",
    "sns.heatmap(corr, mask=np.zeros_like(corr, dtype=np.bool), cmap=sns.diverging_palette(220, 10, as_cmap=True),\n",
    "            square=True, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can remove all the geolocation points as they are highly corelated and distance is actually derived from these variables\n",
    "# Also we can see that fare amount depends on week, day and date as desplayed in following scatter graphs\n",
    "\n",
    "train = train.drop(['pickup_longitude', 'pickup_latitude','dropoff_longitude', 'dropoff_latitude'], axis = 1)\n",
    "test = test.drop(['pickup_longitude', 'pickup_latitude','dropoff_longitude', 'dropoff_latitude'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# How week days affect fare_amount\n",
    "ggplot(train, aes(x = 'weekday', y = 'fare_amount', color='weekday')) + \\\n",
    "    geom_point(alpha = 1, size = 50) + theme_bw()+ ylab(\"fare_amount\") + xlab(\"weekday\") + ggtitle(\"Scatter Plot Analysis weekday vs fare\")\n",
    "# maximum fare is on friday, Monday, Tuesday, wednesday and low fares on Sunday "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Impact of date on fare_amount\n",
    "ggplot(train, aes(x = 'day', y = 'fare_amount', color='weekday')) + \\\n",
    "    geom_point(alpha = 1, size = 50) + theme_bw()+ ylab(\"fare_amount\") + xlab(\"date\") + ggtitle(\"Scatter Plot Analysis date vs fare\")\n",
    "# If fare is affected by date Maximum is around 7th but fare is almost same on all days so date doesnt affect fare amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Impact of hour on fare_amount\n",
    "ggplot(train, aes(x = 'hour', y = 'fare_amount', color='weekday')) + \\\n",
    "    geom_point(alpha = 1, size = 50) + theme_bw()+ ylab(\"fare_amount\") + xlab(\"hour\") + ggtitle(\"Scatter Plot Analysis hour vs fare\")\n",
    "# we can see that fare amount is less in the nights sometimes but mostly alomost same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impact of passenger count on fare\n",
    "ggplot(train, aes(x = 'passenger_count', y = 'fare_amount', color='weekday')) + \\\n",
    "    geom_point(alpha = 1, size = 50) + theme_bw()+ ylab(\"Fare\") + xlab(\"Passenger Count\") + ggtitle(\"Scatter Plot Analysis passenger count vs fare\")\n",
    "\n",
    "# If fare is affected by passenger count, highest when passenger count is 1-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distance impact on fare amount \n",
    "ggplot(train, aes(x = 'distance', y = 'fare_amount',color = 'weekday')) + \\\n",
    "    geom_point(alpha = 1, size = 50) + theme_bw()+ ylab(\"Fare\") + xlab(\"Distance\") + ggtitle(\"Scatter Plot Analysis distance vs fare\")\n",
    "#We can see thta more the distane more the fare, so clearly fare amount is highly positively corelated with distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature scaling is always for continuous variables\n",
    "#Normality check\n",
    "ggplot(train, aes(x = 'passenger_count')) + geom_histogram(fill=\"DarkSlateBlue\", colour = \"black\") +\\\n",
    "    geom_density() +\\\n",
    "    theme_bw() + xlab(\"passenger_count\") + ylab(\"Frequency\") + ggtitle(\"Passenger Count Analysis\") +\\\n",
    "    theme(text=element_text(size=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ggplot(train, aes(x = 'distance')) + geom_histogram(fill=\"Green\", colour = \"black\") +\\\n",
    "    geom_density() +\\\n",
    "    theme_bw() + xlab(\"distance\") + ylab(\"Frequency\") + ggtitle(\"Distance Normality Analysis\") +\\\n",
    "    theme(text=element_text(size=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ggplot(train, aes(x = 'fare_amount')) + geom_histogram(fill=\"Orange\", colour = \"black\") +\\\n",
    "    geom_density() +\\\n",
    "    theme_bw() + xlab(\"fare_amount\") + ylab(\"Frequency\") + ggtitle(\"Fare Amount Analysis\") +\\\n",
    "    theme(text=element_text(size=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As the data is not equally distributed so we will go with Nomalisation\n",
    "for i in ['passenger_count', 'distance']:\n",
    "    print(i)\n",
    "    train[i] = (train[i] - min(train[i]))/(max(train[i]) - min(train[i]))\n",
    "    test[i] = (test[i] - min(test[i]))/(max(test[i]) - min(test[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train.copy()\n",
    "#train = x.copy()\n",
    "# we need to sample train data again in test and train so that we can apply model on sample \n",
    "from sklearn.model_selection import train_test_split\n",
    "train,test1 = train_test_split(train,test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for linear regression we need continuous variables so convert  all the data in numeric\n",
    "train_linear = train.copy()\n",
    "test1_linear = test1.copy()\n",
    "for j in [train_linear,test1_linear]:\n",
    "    for i in range(0, j.shape[1]):\n",
    "        if(j.iloc[:,i].dtypes == \"object\"):\n",
    "            j.iloc[:,i] = pd.to_numeric(j.iloc[:,i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First start with Linear Regression\n",
    "#Import Libraries for LR\n",
    "#import models for libear regression\n",
    "# As  the target v\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train models using the training sets (optimum least swuare method to calculate coefficient)\n",
    "#parameters dependent variable , independent variables\n",
    "lmodel = sm.OLS(train_linear.iloc[:,7], train_linear.iloc[:,0:7]).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmodel.summary()\n",
    "#rSquared 79.7%  dependent variable can be is explained by independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_prediction = lmodel.predict(test1_linear.iloc[:,0:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate MAPE\n",
    "def mape(y_true,y_pred):\n",
    "    #print(np.mean(abs((y_true-y_pred)/y_true)))*100\n",
    "    return 'Test MAPE : %.3f' % (np.mean(abs((y_true-y_pred)/y_true))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Caclulate RMSE\n",
    "from sklearn.metrics import mean_squared_error\n",
    "def RMSE (y_true,y_pred):\n",
    "    return(\"Test RMSE: %.3f\" % mean_squared_error(y_true, y_pred) ** 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mape(test1_linear.iloc[:,7],lr_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE(test1_linear.iloc[:,7],lr_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train = x.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Regression Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decision Tree for regression (max_depth = 2 means max branch for any node should be 2)\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "DT_regression = DecisionTreeRegressor(max_depth = 7).fit(train.iloc[:,0:7],train.iloc[:,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply Data model on Test\n",
    "DT_prediction = DT_regression.predict(test1.iloc[:,0:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mape(test1.iloc[:,7],DT_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE(test1.iloc[:,7],DT_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_Model = RandomForestRegressor(n_estimators=150).fit(train.iloc[:,0:7],train.iloc[:,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_prediction = RF_Model.predict(test1.iloc[:,0:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mape(test1.iloc[:,7],RF_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE(test1.iloc[:,7],RF_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN ML Algo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "KN_Model = KNeighborsRegressor(n_neighbors=60).fit(train.iloc[:,0:7],train.iloc[:,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KN_prediction = KN_Model.predict(test1.iloc[:,0:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mape(test1.iloc[:,7],KN_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE(test1.iloc[:,7],KN_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Predictor is Random Decision Tree so predict actual test data using DT and save it in CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"fare_amount\"]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test =pd.DataFrame(RF_Model.predict(test.iloc[:,0:7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"fare_amount\"]=final_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_submission = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_submission[\"fare_amount\"] = final_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_predict_submission = input(\"Please enter path of final test submission file:(csv)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_submission.to_csv(output_predict_submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
